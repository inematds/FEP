# Ajuste de Par√¢metros de Modelo

## Introdu√ß√£o

O **ajuste de par√¢metros** permite controlar o comportamento do modelo **al√©m do texto do prompt**. Enquanto o prompt define "o que" voc√™ quer, os par√¢metros controlam "como" o modelo gera a resposta.

Par√¢metros como temperature, top-p, max tokens, e penalties oferecem **fine-tuning entre criatividade e precis√£o**, entre determinismo e aleatoriedade.

Dominar par√¢metros √© essencial para obter resultados consistentes e otimizados em produ√ß√£o.

---

## Por que Par√¢metros Importam?

### O Prompt N√£o √© Tudo

Mesmo com um prompt perfeito, par√¢metros incorretos podem arruinar o output:

- **An√°lise de dados com temperature alta** ‚Üí respostas inconsistentes
- **Brainstorming com temperature baixa** ‚Üí ideias gen√©ricas e previs√≠veis
- **Max tokens muito baixo** ‚Üí resposta cortada no meio
- **Penalties mal configuradas** ‚Üí repeti√ß√£o ou diversidade excessiva

### Casos de Uso Diferentes = Par√¢metros Diferentes

| Caso de Uso | Temperature | Top-P | Max Tokens | Penalties |
|-------------|-------------|-------|------------|-----------|
| C√≥digo | 0.0-0.2 | 0.1 | Alto | Baixa |
| An√°lise de dados | 0.1-0.3 | 0.1-0.3 | M√©dio | Baixa |
| Escrita t√©cnica | 0.3-0.5 | 0.5 | Alto | M√©dia |
| Conte√∫do criativo | 0.7-0.9 | 0.9 | Alto | Alta |
| Brainstorming | 0.8-1.0 | 0.95 | M√©dio | Alta |

---

## Par√¢metros Principais

### 1. Temperature (0.0 - 2.0)

**O que faz:** Controla a **aleatoriedade** e **criatividade** das respostas.

#### Como Funciona Tecnicamente

Quando o modelo gera texto, ele calcula probabilidades para cada poss√≠vel pr√≥ximo token:

```
Pr√≥ximas palavras poss√≠veis:
- "√©" ‚Üí 45%
- "era" ‚Üí 30%
- "foi" ‚Üí 15%
- "est√°" ‚Üí 8%
- "seria" ‚Üí 2%
```

**Temperature modifica essas probabilidades:**

**Temperature = 0.0 (Determin√≠stico)**
- Sempre escolhe a op√ß√£o mais prov√°vel
- 100% previs√≠vel
- Sem aleatoriedade

**Temperature = 0.5 (Equilibrado)**
- Probabilidades ajustadas moderadamente
- Mix de previsibilidade e varia√ß√£o

**Temperature = 1.0 (Alta criatividade)**
- Probabilidades achatadas
- Tokens menos prov√°veis t√™m mais chance
- Respostas mais diversas e surpreendentes

---

#### Temperature Baixa (0.0 - 0.3)

**Caracter√≠sticas:**
- ‚úÖ Respostas determin√≠sticas e consistentes
- ‚úÖ Foca em tokens mais prov√°veis
- ‚úÖ Previs√≠vel e factual
- ‚úÖ Ideal para tarefas com resposta "certa"

**Quando usar:**
- C√≥digo e programa√ß√£o
- An√°lise de dados
- Tarefas factuais (tradu√ß√£o, extra√ß√£o)
- Matem√°tica e l√≥gica
- Quando precisa repetibilidade

**Exemplo:**
```
Prompt: "Complete: A capital do Brasil √©..."

Temperature 0.0:
"Bras√≠lia."

Temperature 0.0 (segunda vez):
"Bras√≠lia."  [mesma resposta]
```

---

#### Temperature M√©dia (0.4 - 0.7)

**Caracter√≠sticas:**
- ‚úÖ Equil√≠brio entre criatividade e consist√™ncia
- ‚úÖ Respostas variadas mas sensatas
- ‚úÖ Boa para conversa√ß√£o natural

**Quando usar:**
- Conversa√ß√£o geral
- Explica√ß√µes e tutoriais
- Conte√∫do educacional
- Atendimento ao cliente
- Casos de uso gerais

**Exemplo:**
```
Prompt: "Descreva o outono em uma frase."

Temperature 0.5 (1¬™ vez):
"O outono traz folhas douradas e temperaturas amenas."

Temperature 0.5 (2¬™ vez):
"Folhas caem suavemente enquanto o ar fica mais fresco."
```

---

#### Temperature Alta (0.8 - 1.5)

**Caracter√≠sticas:**
- ‚úÖ Respostas criativas e diversas
- ‚úÖ Vocabul√°rio rico e variado
- ‚úÖ Surpreendente e original
- ‚ö†Ô∏è Pode ser inconsistente
- ‚ö†Ô∏è Maior risco de "nonsense"

**Quando usar:**
- Brainstorming e idea√ß√£o
- Escrita criativa (hist√≥rias, poesia)
- Gera√ß√£o de nomes/t√≠tulos
- Quando diversidade √© prioridade
- Explora√ß√µes criativas

**Exemplo:**
```
Prompt: "Crie nome para app de medita√ß√£o."

Temperature 0.9:
- "Respiro Sereno"
- "Mindful Echo"
- "Pausa Interior"
- "Zen Pulse"

Temperature 0.2:
- "App de Medita√ß√£o"
- "Medita√ß√£o Guiada"
- "Medita F√°cil"  [nomes √≥bvios/gen√©ricos]
```

---

### 2. Top-P / Nucleus Sampling (0.0 - 1.0)

**O que faz:** Controla a **diversidade de tokens** considerados durante a gera√ß√£o.

#### Como Funciona

Top-P considera apenas os tokens cuja probabilidade cumulativa soma at√© P.

**Exemplo visual:**

```
Tokens poss√≠veis com probabilidades:
1. "o" ‚Üí 40%
2. "a" ‚Üí 30%
3. "um" ‚Üí 15%
4. "uma" ‚Üí 10%
5. "este" ‚Üí 3%
6. "aquele" ‚Üí 2%

Top-P = 0.7 (70%):
Considera apenas tokens 1 e 2 (40% + 30% = 70%)

Top-P = 0.95 (95%):
Considera tokens 1-5 (soma 98%)
```

---

#### Top-P Baixo (0.1 - 0.5)

**Comportamento:**
- Considera apenas tokens altamente prov√°veis
- Respostas focadas e previs√≠veis
- Menos diversidade

**Quando usar:**
- Tarefas factuais
- C√≥digo
- Quando precisa consist√™ncia m√°xima

---

#### Top-P Alto (0.9 - 1.0)

**Comportamento:**
- Considera ampla variedade de tokens
- Permite criatividade e diversidade
- Respostas menos previs√≠veis

**Quando usar:**
- Escrita criativa
- Brainstorming
- Quando diversidade √© desej√°vel

---

### ‚ö†Ô∏è Temperature vs Top-P

**Importante:** Temperature e Top-P t√™m efeitos similares.

**Recomenda√ß√£o:**
- Ajuste **UM** deles, n√£o ambos simultaneamente
- Padr√£o comum: Top-P fixo (0.9-1.0), variar Temperature
- OU: Temperature fixa (0.7), variar Top-P

---

### 3. Max Tokens (Completion Length)

**O que faz:** Limita o **tamanho m√°ximo da resposta** gerada.

#### Como Funciona

- Define n√∫mero m√°ximo de tokens no output
- Modelo para quando atinge o limite (pode cortar no meio!)
- N√£o garante que vai usar tudo (pode terminar antes)

---

#### Estrat√©gias de Uso

**Respostas Curtas (50-150 tokens)**
```
Use quando:
- Respostas tipo "sim/n√£o" com justificativa
- Resumos de 2-3 frases
- Descriptions curtas
```

**Respostas M√©dias (200-500 tokens)**
```
Use quando:
- Explica√ß√µes de conceitos
- An√°lises estruturadas
- Emails e mensagens
```

**Respostas Longas (1000+ tokens)**
```
Use quando:
- Artigos e conte√∫do extenso
- An√°lises profundas
- Documenta√ß√£o
- C√≥digo complexo
```

---

#### ‚ö†Ô∏è Armadilhas Comuns

**Problema 1: Max Tokens Muito Baixo**
```
Max Tokens: 50
Prompt: "Escreva tutorial completo de Git"

Output:
"Git √© um sistema de controle de vers√£o. Para come√ßar,
instale usando..."  [CORTADO]
```

**Solu√ß√£o:** Sempre deixe margem (se precisa 100, configure 150).

---

**Problema 2: N√£o Considerar Prompt + Output**
```
Context Window: 4000 tokens
Prompt: 3900 tokens
Max Tokens: 500

Resultado: ERRO (3900 + 500 > 4000)
```

**Solu√ß√£o:** Max Tokens ‚â§ (Context Window - Prompt Tokens - Margem)

---

### 4. Presence Penalty (-2.0 - 2.0)

**O que faz:** Penaliza **t√≥picos** que j√° foram mencionados.

#### Como Funciona

- **0.0:** Sem penaliza√ß√£o (padr√£o)
- **Positivo (0.1 - 1.0):** Encoraja diversidade de t√≥picos
- **Negativo:** Encoraja repeti√ß√£o de t√≥picos (raramente √∫til)

#### Quando Usar

**Presence Penalty Positiva (0.3 - 0.6):**
```
Use quando:
- Listagens (quer cobertura ampla)
- Brainstorming (quer ideias diversas)
- Evitar que modelo "fique preso" em um t√≥pico
```

**Exemplo:**
```
Prompt: "Liste 10 estrat√©gias de marketing digital"

Presence Penalty = 0.0:
1. Marketing de conte√∫do
2. Marketing de conte√∫do em blog
3. Marketing de conte√∫do em v√≠deo
4. Marketing de conte√∫do em podcast
[muito repetitivo]

Presence Penalty = 0.6:
1. Marketing de conte√∫do
2. SEO e otimiza√ß√£o
3. Email marketing
4. Social media ads
5. Influencer partnerships
[mais diverso]
```

---

### 5. Frequency Penalty (-2.0 - 2.0)

**O que faz:** Penaliza **tokens espec√≠ficos** que j√° apareceram.

#### Como Funciona

- **0.0:** Sem penaliza√ß√£o
- **Positivo (0.1 - 1.0):** Reduz repeti√ß√£o de palavras
- **Negativo:** Encoraja repeti√ß√£o (raramente √∫til)

#### Quando Usar

**Frequency Penalty Positiva (0.3 - 0.6):**
```
Use quando:
- Quer variedade vocabular
- Evitar que mesma palavra apare√ßa m√∫ltiplas vezes
- Texto fica repetitivo
```

**Exemplo:**
```
Frequency Penalty = 0.0:
"O produto √© √≥timo. A qualidade do produto impressiona.
O produto superou expectativas."
[palavra "produto" repetida 3x]

Frequency Penalty = 0.5:
"O produto √© √≥timo. A qualidade impressiona.
Este item superou expectativas."
[varia√ß√£o vocabular]
```

---

## Par√¢metros por Caso de Uso

### C√≥digo e Programa√ß√£o

```json
{
  "temperature": 0.0,
  "top_p": 0.1,
  "max_tokens": 2000,
  "presence_penalty": 0.0,
  "frequency_penalty": 0.0
}
```

**Rationale:**
- Temperature 0.0: C√≥digo precisa ser correto e determin√≠stico
- Top-P baixo: Foque em padr√µes mais prov√°veis (melhores pr√°ticas)
- Max tokens alto: C√≥digo pode ser longo
- Sem penalties: C√≥digo muitas vezes repete padr√µes (loops, etc.)

---

### An√°lise de Dados

```json
{
  "temperature": 0.2,
  "top_p": 0.3,
  "max_tokens": 800,
  "presence_penalty": 0.0,
  "frequency_penalty": 0.1
}
```

**Rationale:**
- Temperature baixa: Precis√£o e consist√™ncia
- Max tokens m√©dio: An√°lises estruturadas mas n√£o excessivas
- Frequency penalty baixa: Evita repetir mesmos n√∫meros/termos

---

### Conte√∫do Criativo (Blog, Marketing)

```json
{
  "temperature": 0.7,
  "top_p": 0.9,
  "max_tokens": 1500,
  "presence_penalty": 0.3,
  "frequency_penalty": 0.4
}
```

**Rationale:**
- Temperature m√©dia-alta: Criatividade mas coer√™ncia
- Presence penalty: Cobre diversos t√≥picos
- Frequency penalty: Vocabul√°rio rico e variado

---

### Brainstorming

```json
{
  "temperature": 0.9,
  "top_p": 0.95,
  "max_tokens": 500,
  "presence_penalty": 0.6,
  "frequency_penalty": 0.6
}
```

**Rationale:**
- Temperature alta: M√°xima criatividade
- Penalties altas: For√ßa diversidade de ideias
- Max tokens m√©dio: Lista de ideias, n√£o ensaios

---

### Conversa√ß√£o / Chatbot

```json
{
  "temperature": 0.6,
  "top_p": 0.85,
  "max_tokens": 300,
  "presence_penalty": 0.2,
  "frequency_penalty": 0.3
}
```

**Rationale:**
- Temperature m√©dia: Natural mas n√£o muito aleat√≥rio
- Max tokens baixo: Respostas conversacionais e concisas
- Penalties leves: Alguma variedade sem perder foco

---

## Experimenta√ß√£o e Otimiza√ß√£o

### Processo de Ajuste

**Step 1: Baseline**
```
Comece com valores padr√£o:
- Temperature: 0.7
- Top-P: 1.0
- Max Tokens: adequado √† tarefa
- Penalties: 0.0
```

**Step 2: Ajuste Prim√°rio (Temperature)**
```
Teste 3 valores:
- Baixo (0.2)
- M√©dio (0.6)
- Alto (0.9)

Escolha o que melhor se encaixa.
```

**Step 3: Fine-Tuning (Penalties)**
```
Se necess√°rio, ajuste penalties:
- Texto muito repetitivo? ‚Üí Aumente frequency penalty
- Falta diversidade de t√≥picos? ‚Üí Aumente presence penalty
```

**Step 4: Valida√ß√£o**
```
Teste configura√ß√£o final em 5-10 exemplos
Verifique consist√™ncia e qualidade
```

---

### A/B Testing de Par√¢metros

**Metodologia:**

1. **Defina m√©trica de sucesso**
   - Precis√£o
   - Criatividade
   - Ader√™ncia a guidelines
   - Satisfa√ß√£o do usu√°rio

2. **Teste varia√ß√µes**
   ```
   Configura√ß√£o A: Temperature 0.3
   Configura√ß√£o B: Temperature 0.7

   Rode cada uma em 20 prompts id√™nticos
   ```

3. **Compare resultados**
   - Qual configura√ß√£o ganha na m√©trica?
   - H√° trade-offs?
   - Diferen√ßa √© significativa?

4. **Implemente vencedor**

---

## Erros Comuns e Como Evitar

### ‚ùå Erro 1: Ajustar Tudo Simultaneamente

**Problema:**
```
Mudar temperature, top-p, e penalties ao mesmo tempo
‚Üí Imposs√≠vel saber o que causou melhoria ou piora
```

**Solu√ß√£o:**
```
Ajuste UM par√¢metro por vez
Valide o efeito
S√≥ ent√£o ajuste o pr√≥ximo
```

---

### ‚ùå Erro 2: Temperature Muito Alta para Tarefas Factuais

**Problema:**
```json
{
  "temperature": 0.9,
  "prompt": "Calcule: 127 * 43"
}

Output: "5.461" ‚ùå (resposta correta: 5.461... ou talvez cria algo errado)
```

**Solu√ß√£o:**
```
Tarefas com resposta certa = Temperature ‚â§ 0.3
```

---

### ‚ùå Erro 3: Max Tokens Muito Restritivo

**Problema:**
```
Max Tokens: 100
Prompt: "Escreva tutorial completo de React"

Output cortado no meio da frase...
```

**Solu√ß√£o:**
```
Sempre adicione 30-50% de margem ao max tokens estimado
```

---

### ‚ùå Erro 4: Ignorar Custos

**Problema:**
```
Max Tokens: 4000 (sempre)
Mesmo quando resposta s√≥ precisa de 100 tokens
‚Üí Paga por tokens n√£o usados
```

**Solu√ß√£o:**
```
Ajuste max tokens ao esperado para cada task
Monitore tokens realmente usados
Otimize configura√ß√£o
```

---

### ‚ùå Erro 5: Configura√ß√£o √önica para Tudo

**Problema:**
```
Usar mesmos par√¢metros para:
- C√≥digo
- Marketing copy
- An√°lise de dados
- Brainstorming

Resultados sub√≥timos em todos
```

**Solu√ß√£o:**
```
Crie PROFILES de par√¢metros:
- profile_code = {temperature: 0.0, ...}
- profile_creative = {temperature: 0.8, ...}
- profile_analysis = {temperature: 0.2, ...}
```

---

## Implementa√ß√£o Pr√°tica

### Exemplo em Python (API Claude)

```python
import anthropic

client = anthropic.Anthropic(api_key="...")

# Profile para c√≥digo
def generate_code(prompt):
    response = client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=2000,
        temperature=0.0,  # Determin√≠stico
        messages=[{"role": "user", "content": prompt}]
    )
    return response.content[0].text

# Profile para brainstorming
def brainstorm_ideas(prompt):
    response = client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=500,
        temperature=0.9,  # Criativo
        top_p=0.95,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.content[0].text

# Uso
code = generate_code("Crie fun√ß√£o Python para ordenar lista")
ideas = brainstorm_ideas("10 nomes para app de fitness")
```

---

### Sistema de Profiles

```python
PARAMETER_PROFILES = {
    "code": {
        "temperature": 0.0,
        "top_p": 0.1,
        "max_tokens": 2000,
    },
    "analysis": {
        "temperature": 0.2,
        "max_tokens": 1000,
    },
    "creative": {
        "temperature": 0.8,
        "top_p": 0.95,
        "max_tokens": 1500,
        "presence_penalty": 0.4,
        "frequency_penalty": 0.4,
    },
    "brainstorm": {
        "temperature": 0.9,
        "max_tokens": 500,
        "presence_penalty": 0.6,
        "frequency_penalty": 0.6,
    },
}

def generate(prompt, profile="analysis"):
    params = PARAMETER_PROFILES[profile]
    response = client.messages.create(
        model="claude-3-5-sonnet-20241022",
        messages=[{"role": "user", "content": prompt}],
        **params
    )
    return response.content[0].text
```

---

## Monitoramento e M√©tricas

### O que Monitorar em Produ√ß√£o

1. **Token Usage**
   ```
   - Tokens por request (prompt + completion)
   - Custo por request
   - Desperd√≠cio (max_tokens vs usado)
   ```

2. **Qualidade de Output**
   ```
   - Taxa de outputs truncados
   - Taxa de regenera√ß√£o necess√°ria
   - Satisfa√ß√£o do usu√°rio
   ```

3. **Performance**
   ```
   - Lat√™ncia por configura√ß√£o
   - Success rate
   ```

---

## Cheat Sheet - Guia R√°pido

| Task | Temp | Top-P | Max Tok | Pres | Freq |
|------|------|-------|---------|------|------|
| **C√≥digo** | 0.0-0.2 | 0.1 | Alto | 0.0 | 0.0 |
| **An√°lise** | 0.1-0.3 | 0.3 | M√©dio | 0.0 | 0.1 |
| **Tutorial** | 0.3-0.5 | 0.5 | Alto | 0.1 | 0.2 |
| **Marketing** | 0.7-0.8 | 0.9 | Alto | 0.3 | 0.4 |
| **Brainstorm** | 0.8-1.0 | 0.95 | M√©dio | 0.6 | 0.6 |
| **Chat** | 0.6-0.7 | 0.85 | Baixo | 0.2 | 0.3 |
| **Criativo** | 0.8-0.9 | 0.9 | Alto | 0.4 | 0.5 |

---

## Recursos Adicionais

### Ferramentas

- **OpenAI Playground:** Interface visual para testar par√¢metros
- **Anthropic Console:** Testar Claude com diferentes configs
- **LangChain:** Framework com parameter management
- **Weights & Biases:** Track experiments com par√¢metros

### Leituras

- üìñ Documenta√ß√£o oficial da API (OpenAI, Anthropic, etc.)
- üéì "Temperature in Language Models" research papers
- üìä Benchmarks de par√¢metros por task type
- üî¨ Experimentos da comunidade (GitHub, papers)

---

## Exerc√≠cio Pr√°tico

**Desafio:** Otimize par√¢metros para seu caso de uso.

1. **Escolha uma task recorrente sua**

2. **Teste 3 configura√ß√µes:**
   ```
   Config A (conservadora): Temp 0.2
   Config B (balanceada): Temp 0.6
   Config C (criativa): Temp 0.9
   ```

3. **Rode cada config em 5 prompts id√™nticos**

4. **Compare:**
   - Qual teve melhor qualidade?
   - Qual foi mais consistente?
   - H√° trade-offs?

5. **Fine-tune vencedor** ajustando penalties se necess√°rio

6. **Documente** a configura√ß√£o ideal para refer√™ncia

---

## Conclus√£o

Par√¢metros s√£o ferramentas poderosas para controlar comportamento do LLM al√©m do prompt. Dominar par√¢metros permite:

- ‚úÖ Resultados mais consistentes
- ‚úÖ Otimiza√ß√£o para cada caso de uso
- ‚úÖ Economia de custo (max tokens otimizado)
- ‚úÖ Melhor experi√™ncia do usu√°rio

**Lembre-se:**
- Par√¢metros N√ÉO substituem prompts bem escritos
- Ajuste um par√¢metro por vez
- Documente configura√ß√µes que funcionam
- Monitore em produ√ß√£o

**Pr√≥ximo passo:** Crie sua biblioteca de parameter profiles para casos de uso comuns. Voc√™ ganhar√° velocidade e consist√™ncia!
